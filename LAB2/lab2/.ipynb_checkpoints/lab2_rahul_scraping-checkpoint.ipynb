{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://github.com/Harvard-IACS/2018-CS109A/blob/master/content/styles/iacs.png?raw=true\"> CS109A Introduction to Data Science \n",
    "\n",
    "## Lab 2 Scraping\n",
    "\n",
    "**Harvard University**<br>\n",
    "**Summer 2018**<br>\n",
    "**Instructors:** Pavlos Protopapas and Kevin Rader <br>\n",
    "**Lab Instructors:** Rahul Dave <br>\n",
    "**Authors:** Rahul Dave, David Sondak, Will Claybaugh and Pavlos Protopaps\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RUN THIS CELL TO GET THE RIGHT FORMATTING \n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"../../styles/cs109.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eleni/anaconda2/envs/bunny/lib/python3.6/site-packages/seaborn/apionly.py:6: UserWarning: As seaborn no longer sets a default style on import, the seaborn.apionly module is deprecated. It will be removed in a future version.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn.apionly as sns\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents \n",
    "<ol start=\"0\">\n",
    "<li> Learning Goals </li>\n",
    "<li> Exploring the Web pages and downloading them</li>\n",
    "<li> Parse the page, extract book urls </li>\n",
    "<li> Parse a book page, extract book properties </li>\n",
    "<li> Set up a pipeline for fetching and parsing</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "\n",
    "BLA BLA\n",
    "\n",
    "*This lab corresponds to lectures 2, 3 and 4 and maps on to homework 1 and further.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploring the web pages and downloading them\n",
    "\n",
    "We're going to see the structure of Goodread's best books list. We'll use the Developer tools in chrome, safari and firefox have similar tools available\n",
    "\n",
    "![](images/goodreads1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To getch this page we use the `requests` module. But are we allowed to do this? Lets check:\n",
    "\n",
    "https://www.goodreads.com/robots.txt\n",
    "\n",
    "Yes we are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.goodreads.com/list/show/1.Best_Books_Ever?page=1\n"
     ]
    }
   ],
   "source": [
    "URLSTART=\"https://www.goodreads.com\"\n",
    "BESTBOOKS=\"/list/show/1.Best_Books_Ever?page=\"\n",
    "url = URLSTART+BESTBOOKS+'1'\n",
    "print(url)\n",
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see properties of the page. Most relevant are `status_code` and `text`. The former tells us  if the web-page was found, and if found , ok. (See lecture notes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.status_code # 200 is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html class=\"desktop\\n\">\\n\\n\\n<head>\\n  <title>\\nBest Books Ever (54257 books)\\n</title>\\n\\n\\n    <script type=\"text/javascript\"> var ue_t0=window.ue_t0||+new Date();\\n </script>\\n  <script type=\"text/javascript\">\\n    (function(e){var c=e;var a=c.ue||{};a.main_scope=\"mainscopecsm\";a.q=[];a.t0=c.ue_t0||+new Date();a.d=g;function g(h){return +new Date()-(h?0:a.t0)}function d(h){return function(){a.q.push({n:h,a:arguments,t:a.d()})}}function b(m,l,h,j,i){var k={m:m,f:l,l:h,c:\"\"+j,err:i,fromOnError:1,args:arguments};c.ueLogError(k);return false}b.skipTrace=1;e.onerror=b;function f(){c.uex(\"ld\")}if(e.addEventListener){e.addEventListener(\"load\",f,false)}else{if(e.attachEvent){e.attachEvent(\"onload\",f)}}a.tag=d(\"tag\");a.log=d(\"log\");a.reset=d(\"rst\");c.ue_csm=c;c.ue=a;c.ueLogError=d(\"err\");c.ues=d(\"ues\");c.uet=d(\"uet\");c.uex=d(\"uex\");c.uet(\"ue\")})(window);(function(e,d){var a=e.ue||{};function c(g){if(!g){return}var f=d.head||d.getElementsByTagName(\"head\")[0]||d.documentElement,h=d.createElement(\"script\");h.async=\"async\";h.src=g;f.insertBefore(h,f.firstChild)}function b(){var k=e.ue_cdn||\"z-ecx.images-amazon.com\",g=e.ue_cdns||\"images-na.ssl-images-amazon.com\",j=\"/images/G/01/csminstrumentation/\",h=e.ue_file||\"ue-full-11e51f253e8ad9d145f4ed644b40f692._V1_.js\",f,i;if(h.indexOf(\"NSTRUMENTATION_FIL\")>=0){return}if(\"ue_https\" in e){f=e.ue_https}else{f=e.location&&e.location.protocol==\"https:\"?1:0}i=f?\"https://\":\"http://\";i+=f?g:k;i+=j;i+=h;c(i)}if(!e.ue_inline){if(a.loadUEFull){a.loadUEFull()}else{b()}}a.uels=c;e.ue=a})(window,document);\\n\\n    if (window.ue && window.ue.tag) { window.ue.tag(\\'list:show:signed_out\\', ue.main_scope);window.ue.tag(\\'list:show:signed_out:desktop\\', ue.main_scope); }\\n  </script>\\n\\n\\n\\n          <script type=\"text/javascript\">\\n        if (window.Mobvious === undefined) {\\n          window.Mobvious = {};\\n        }\\n        window.Mobvious.device_type = \\'desktop\\';\\n        </script>\\n\\n\\n  \\n<script src=\"https://s.gr-assets.com/assets/webfontloader-d12a76562d1fabc96ea2ca165a5f46ae.js\"></script>\\n<script>\\n//<![CDATA[\\n\\n  WebFont.load({\\n    classes: false,\\n    custom: {\\n      families: [\"Lato:n4,n7,i4\", \"Merriweather:n4,n7,i4\"],\\n      urls: [\"https://s.gr-assets.com/assets/gr/fonts-e256f84093cc13b27f5b82343398031a.css\"]\\n    }\\n  });\\n\\n//]]>\\n</script>\\n\\n  <link rel=\"stylesheet\" media=\"all\" href=\"https://s.gr-assets.com/assets/goodreads-c15ec855d4f1ae48d3de601b66e101c3.css\" />\\n<!--[if lte IE 9]>\\n<link rel=\"stylesheet\" media=\"all\" href=\"https://s.gr-assets.com/assets/goodreads_split2-5638a74aff000b11941f7f917a20057e.css\" />\\n<![endif]-->\\n    <style type=\"text/css\" media=\"screen\">\\n    .bigTabs {\\n      margin-bottom: 10px;\\n    }\\n\\n    .list_read{\\n      background-color: #D7D2C4;\\n      float: left;\\n    }\\n  </style>\\n\\n\\n  <!--[if lt IE 9]>\\n    <link rel=\"stylesheet\" media=\"screen\" href=\"https://s.gr-assets.com/assets/ie-243e73b5c2539766a7d02b37fdf277f8.css\" />\\n  <![endif]-->\\n\\n  <!--[if lt IE 8]>\\n    <link rel=\"stylesheet\" media=\"screen\" href=\"https://s.gr-assets.com/assets/common_images_ie-5b0cc205c33756d8e7e84ce5b8be28e3.css\" />\\n  <![endif]-->\\n\\n  <!--[if gte IE 8]><!-->\\n  <link rel=\"stylesheet\" media=\"screen\" href=\"https://s.gr-assets.com/assets/common_images-67dd60a681af04727cf7d18f5c5ba498.css\" />\\n  <!--<![endif]-->\\n\\n  <script src=\"https://s.gr-assets.com/assets/desktop/libraries-9f9d1f3b2000952a2489f5e14d4efa53.js\"></script>\\n  <script src=\"https://s.gr-assets.com/assets/application-806e743c71f50883a327d3870227d2d0.js\"></script>\\n\\n    <script>\\n  //<![CDATA[\\n    var gptAdSlots = gptAdSlots || [];\\n    var googletag = googletag || {};\\n    googletag.cmd = googletag.cmd || [];\\n    (function() {\\n      var gads = document.createElement(\"script\");\\n      gads.async = true;\\n      gads.type = \"text/javascript\";\\n      var useSSL = \"https:\" == document.location.protocol;\\n      gads.src = (useSSL ? \"https:\" : \"http:\") +\\n      \"//www.googletagservices.com/tag/js/gpt.js\";\\n      var node = document.getElementsByTagName(\"script\")[0];\\n      node.parentNode.insertBefore(gads, node);\\n    })();\\n    // page settings\\n  //]]>\\n</script>\\n<script>\\n  //<![CDATA[\\n    googletag.cmd.push(function() {\\n      googletag.pubads().setTargeting(\"sid\", \"14f295bdfe75d7a8783d5c7153f87f59\");\\n    googletag.pubads().setTargeting(\"grsession\", \"14f295bdfe75d7a8783d5c7153f87f59\");\\n    googletag.pubads().setTargeting(\"surface\", \"desktop\");\\n    googletag.pubads().setTargeting(\"signedin\", \"false\");\\n    googletag.pubads().setTargeting(\"gr_author\", \"false\");\\n    googletag.pubads().setTargeting(\"author\", []);\\n    googletag.pubads().setTargeting(\"shelf\", [\"best\",\"earliestlist\",\"favourites\",\"fiction\",\"writer\"]);\\n    googletag.pubads().setTargeting(\"gtargeting\", \"1z141z5\");\\n    googletag.pubads().setTargeting(\"resource\", \"List_1\");\\n      googletag.pubads().enableAsyncRendering();\\n      googletag.pubads().enableSingleRequest();\\n      googletag.pubads().collapseEmptyDivs(true);\\n      googletag.pubads().disableInitialLoad();\\n      googletag.enableServices();\\n    });\\n  //]]>\\n</scr'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.text[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us write a loop to fetch 2 pages of \"best-books\" from goodreads. Notice the use of a format string. This is an example of old-style python format strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FTW page01.html\n",
      "FTW page02.html\n"
     ]
    }
   ],
   "source": [
    "URLSTART=\"https://www.goodreads.com\"\n",
    "BESTBOOKS=\"/list/show/1.Best_Books_Ever?page=\"\n",
    "for i in range(1,3):\n",
    "    bookpage=str(i)\n",
    "    stuff=requests.get(URLSTART+BESTBOOKS+bookpage)\n",
    "    filetowrite=\"page\"+ '%02d' % i + \".html\"\n",
    "    print(\"FTW\", filetowrite)\n",
    "    fd=open(filetowrite,\"w\")\n",
    "    fd.write(stuff.text)\n",
    "    fd.close()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parse the page, extract book urls\n",
    "\n",
    "Notice how we do file input-output, and use beautiful soup in the code below. The `with` construct ensures that the file being read is closed, something we do explicitly for the file being written. We look for the elements with class `bookTitle`, extract the urls, and write them into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookdict={}\n",
    "for i in range(1,3):\n",
    "    books=[]\n",
    "    stri = '%02d' % i\n",
    "    filetoread=\"page\"+ stri + '.html'\n",
    "    print(\"FTW\", filetoread)\n",
    "    with open(filetoread) as fdr:\n",
    "        data = fdr.read()\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "    for e in soup.select('.bookTitle'):\n",
    "        books.append(e['href'])\n",
    "    print(books[:10])\n",
    "    bookdict[stri]=books\n",
    "    fd=open(\"list\"+stri+\".txt\",\"w\")\n",
    "    fd.write(\"\\n\".join(books))\n",
    "    fd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is George Orwell's 1984"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookdict['02'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Lets go look at the first URLs on both pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/goodreads2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parse a book page, extract book properties\n",
    "\n",
    "Ok so now lets dive in and get one of these these files and parse them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "furl=URLSTART+bookdict['02'][0]\n",
    "furl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/goodreads3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstuff=requests.get(furl)\n",
    "print(fstuff.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=BeautifulSoup(fstuff.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.select(\"meta[property='og:title']\")[0]['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get everything we want..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=BeautifulSoup(fstuff.text, 'html.parser')\n",
    "print(\n",
    "\"title\", d.select_one(\"meta[property='og:title']\")['content'],\"\\n\",\n",
    "\"isbn\", d.select(\"meta[property='books:isbn']\")[0]['content'],\"\\n\",\n",
    "\"type\", d.select(\"meta[property='og:type']\")[0]['content'],\"\\n\",\n",
    "\"author\", d.select(\"meta[property='books:author']\")[0]['content'],\"\\n\",\n",
    "\"average rating\", d.select_one(\"span.average\").text,\"\\n\",\n",
    "\"ratingCount\", d.select(\"meta[itemprop='ratingCount']\")[0][\"content\"],\"\\n\",\n",
    "\"reviewCount\", d.select_one(\"span.count\")[\"title\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we know what to do, lets wrap our fetching into a proper script. So that we dont overwhelm their servers, we will only fetch 5 from each page, but you get the idea...\n",
    "\n",
    "We'll segue of a bit to explore new style format strings. See https://pyformat.info for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"list{:0>2}.txt\".format(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"4\"\n",
    "b = 4\n",
    "class Four:\n",
    "    def __str__(self):\n",
    "        return \"Fourteen\"\n",
    "c=Four()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"The hazy cat jumped over the {} and {} and {}\".format(a, b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set up a pipeline for fetching and parsing\n",
    "\n",
    "Ok lets get back to the fetching..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetched=[]\n",
    "for i in range(1,3):\n",
    "    with open(\"list{:0>2}.txt\".format(i)) as fd:\n",
    "        counter=0\n",
    "        for bookurl_line in fd:\n",
    "            if counter > 4:\n",
    "                break\n",
    "            bookurl=bookurl_line.strip()\n",
    "            stuff=requests.get(URLSTART+bookurl)\n",
    "            filetowrite=bookurl.split('/')[-1]\n",
    "            filetowrite=stri+\"_\"+filetowrite+\".html\"\n",
    "            print(\"FTW\", filetowrite)\n",
    "            fd=open(filetowrite,\"w\")\n",
    "            fd.write(stuff.text)\n",
    "            fd.close()\n",
    "            fetched.append(filetowrite)\n",
    "            time.sleep(2)\n",
    "            counter=counter+1\n",
    "            \n",
    "print(fetched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok we are off to parse each one of the html pages we fetched. We have provided the skeleton of the code and the code to parse the year, since it is a bit more complex...see the difference in the screenshots above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "yearre = r'\\d{4}'\n",
    "def get_year(d):\n",
    "    if d.select_one(\"nobr.greyText\"):\n",
    "        return d.select_one(\"nobr.greyText\").text.strip().split()[-1][:-1]\n",
    "    else:\n",
    "        thetext=d.select(\"div#details div.row\")[1].text.strip()\n",
    "        rowmatch=re.findall(yearre, thetext)\n",
    "        if len(rowmatch) > 0:\n",
    "            rowtext=rowmatch[0].strip()\n",
    "        else:\n",
    "            rowtext=\"NA\"\n",
    "        return rowtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "\n",
    "Your job is to fill in the code to get the genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genres(d):\n",
    "    # your code here\n",
    "    genres=d.select(\"div.elementList div.left a\")\n",
    "    glist=[]\n",
    "    for g in genres:\n",
    "        glist.append(g['href'])\n",
    "    return glist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "listofdicts=[]\n",
    "for filetoread in fetched:\n",
    "    print(filetoread)\n",
    "    td={}\n",
    "    with open(filetoread) as fd:\n",
    "        datext = fd.read()\n",
    "    d=BeautifulSoup(datext, 'html.parser')\n",
    "    td['title']=d.select_one(\"meta[property='og:title']\")['content']\n",
    "    td['isbn']=d.select_one(\"meta[property='books:isbn']\")['content']\n",
    "    td['booktype']=d.select_one(\"meta[property='og:type']\")['content']\n",
    "    td['author']=d.select_one(\"meta[property='books:author']\")['content']\n",
    "    td['rating']=d.select_one(\"span.average\").text\n",
    "    td['ratingCount']=d.select_one(\"meta[itemprop='ratingCount']\")[\"content\"]\n",
    "    td['reviewCount']=d.select_one(\"span.count\")[\"title\"]\n",
    "    td['year'] = get_year(d)\n",
    "    td['file']=filetoread\n",
    "    glist = get_genres(d)\n",
    "    td['genres']=\"|\".join(glist)\n",
    "    listofdicts.append(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofdicts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally lets write all this stuff into a csv file which we will use to do analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(listofdicts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"meta.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
